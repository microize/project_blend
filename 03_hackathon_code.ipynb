{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q gradio numpy pandas scikit-learn openai opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\0.sripathi\\Git_repo_latest\\genai_crew_newsletter_agent\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import cv2\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_generation_request(host,params,):\n",
    "    headers = {\"Accept\": \"image/*\",\"Authorization\": f\"Bearer {STABILITY_KEY}\"}\n",
    "\n",
    "    # Encode parameters\n",
    "    files = {}\n",
    "    image = params.pop(\"image\", None)\n",
    "    mask = params.pop(\"mask\", None)\n",
    "    if image is not None and image != '':\n",
    "        files[\"image\"] = open(image, 'rb')\n",
    "    if mask is not None and mask != '':\n",
    "        files[\"mask\"] = open(mask, 'rb')\n",
    "    if len(files)==0:\n",
    "        files[\"none\"] = ''\n",
    "\n",
    "    # Send request\n",
    "    print(f\"Sending REST request to {host}...\")\n",
    "    response = requests.post(\n",
    "        host,\n",
    "        headers=headers,\n",
    "        files=files,\n",
    "        data=params\n",
    "    )\n",
    "    if not response.ok:\n",
    "        raise Exception(f\"HTTP {response.status_code}: {response.text}\")\n",
    "\n",
    "    return response\n",
    "\n",
    "def send_async_generation_request(\n",
    "    host,\n",
    "    params,\n",
    "):\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {STABILITY_KEY}\"\n",
    "    }\n",
    "\n",
    "    # Encode parameters\n",
    "    files = {}\n",
    "    if \"image\" in params:\n",
    "        image = params.pop(\"image\")\n",
    "        files = {\"image\": open(image, 'rb')}\n",
    "\n",
    "    # Send request\n",
    "    print(f\"Sending REST request to {host}...\")\n",
    "    response = requests.post(\n",
    "        host,\n",
    "        headers=headers,\n",
    "        files=files,\n",
    "        data=params\n",
    "    )\n",
    "    if not response.ok:\n",
    "        raise Exception(f\"HTTP {response.status_code}: {response.text}\")\n",
    "\n",
    "    # Process async response\n",
    "    response_dict = json.loads(response.text)\n",
    "    generation_id = response_dict.get(\"id\", None)\n",
    "    assert generation_id is not None, \"Expected id in response\"\n",
    "\n",
    "    # Loop until result or timeout\n",
    "    timeout = int(os.getenv(\"WORKER_TIMEOUT\", 500))\n",
    "    start = time.time()\n",
    "    status_code = 202\n",
    "    while status_code == 202:\n",
    "        response = requests.get(\n",
    "            f\"{host}/result/{generation_id}\",\n",
    "            headers={\n",
    "                **headers,\n",
    "                \"Accept\": \"image/*\"\n",
    "            },\n",
    "        )\n",
    "\n",
    "        if not response.ok:\n",
    "            raise Exception(f\"HTTP {response.status_code}: {response.text}\")\n",
    "        status_code = response.status_code\n",
    "        time.sleep(10)\n",
    "        if time.time() - start > timeout:\n",
    "            raise Exception(f\"Timeout after {timeout} seconds\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bckgrnd_removal(Im): \n",
    "    image = str(Im)\n",
    "    output_format = \"png\"\n",
    "    host = f\"https://api.stability.ai/v2beta/stable-image/edit/remove-background\"\n",
    "    params = {\"image\" : image,\"output_format\": output_format}\n",
    "    response = send_generation_request(host,params)\n",
    "\n",
    "    # Decode response\n",
    "    output_image = response.content\n",
    "    finish_reason = response.headers.get(\"finish-reason\")\n",
    "    seed = response.headers.get(\"seed\")\n",
    "\n",
    "    # Check for NSFW classification\n",
    "    if finish_reason == 'CONTENT_FILTERED':\n",
    "        raise Warning(\"Generation failed NSFW classifier\")\n",
    "\n",
    "    # Save and display result\n",
    "    filename, _ = os.path.splitext(os.path.basename(image))\n",
    "    bckgrnd_removed_image = f\"data\\\\03_app_generated\\\\01_bckgrnd_removed_image_{filename}_{seed}.{output_format}\"\n",
    "    with open(bckgrnd_removed_image, \"wb\") as f:\n",
    "        f.write(output_image)\n",
    "    return bckgrnd_removed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(text):\n",
    "    # Using regular expressions to split and filter alphanumeric tokens\n",
    "    return [token for token in re.split('[ _]', text) if token.isalnum()]\n",
    "\n",
    "def search_image(prmpt):\n",
    "    df = pd.read_csv(\"data\\\\02_processed\\\\car_image_file_name.csv\")\n",
    "    filenames = df['Filename'].values\n",
    "\n",
    "    # Initialize the TfidfVectorizer with the custom tokenizer\n",
    "    vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer)\n",
    "    X_filenames = vectorizer.fit_transform(filenames)\n",
    "\n",
    "    # Define a user query and vectorize it\n",
    "    user_query = prmpt\n",
    "    X_query = vectorizer.transform([user_query])\n",
    "\n",
    "    # Compute the cosine similarity scores\n",
    "    similarity_scores = cosine_similarity(X_query, X_filenames)\n",
    "\n",
    "    # Create a DataFrame with filenames and their similarity scores\n",
    "    results_df = pd.DataFrame({\n",
    "        'Filename': filenames,\n",
    "        'Similarity Score': similarity_scores.flatten()  # ensure the similarity scores are in the correct shape\n",
    "    })\n",
    "\n",
    "    # Write the results to a CSV file\n",
    "    results_df.to_csv(\"data\\\\02_processed\\\\similarity_scores.csv\", index=False)\n",
    "\n",
    "    sorted_results_df = results_df.sort_values(by='Similarity Score', ascending=False)\n",
    "\n",
    "    # Display the top 10 results\n",
    "    top_6_results = sorted_results_df.head(20)\n",
    "    top_6_results['Filename']= top_6_results['Filename'].apply(lambda x:\"data\\\\02_processed\\\\cv_final_renamed_2\\\\\"+x)\n",
    "    return top_6_results['Filename'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Enhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prmpt_enhancer(rd,prmpt):\n",
    "    gbf_ip_prmpt = f\"Act as expert prompt engineer. I will provide you with a preliminary prompt to generate a background image for a car using inpainting. Step-by-step, identify and integrate unique architectural elements suitable for the setting to enhance its luxuryâ€”refer to the provided examples. In consultation with the art director, refine the background to harmonize with the car's color. Finally, enhance the prompt to ensure it incorporates aesthetically pleasing elements for image generation in Stable Diffusion.Write the final prompt in JSON format with the prompt key.##Prompt:```{prmpt}``` \\n Examples:car before arab home : car with shadow infront of modern arab villa with perforated facade and trees, warm color, villa cover top of the image, hyperrealistic \\n car infront of showroom : Car standing outside 8 Modern artisitic luxury car showroom made of glass with blue sk ,  highly detailed, warm tone , 8k resolution, hyperrealistic \\n car inside showroom :  car on Showroom Floor in luxury glass showroom with decorative screen, Vibrant, enticing, commercial, product-focused, eye-catching, professional, highly detailed, warm tone, hyperrealistic \\n car on mountain: car with shadow  on snow filled path himalayas, top of image is filled with blue sky and snowy mountain, hyperrealistic'\\n car before repair center: car with shadow parked in front of a bustling car repair center with bold digital yellow shop hoarding and blue sky , midday, 8K resolution, hyperrealistic\"\n",
    "    ip_ip_prmpt = f\"Act as expert Prompt Engineer. You will be provided with a prompt. Your task is to infuse expressions to human prompt you receive. Only enhance the expression and dress style; do not add details about the car background or the car color. consult with art director and human behaviour analyst to revamp the prompt. \\n Example Prompt ```A Arab Traditional family standing before car``` transformed to ```8k, Fashion portrait of a traditional Arab family stands proudly in front of their car, exuding a sense of joyful pride.``` Here are similar transformations and enhancements for other scenarios a. 8K, Fashion portrait of a girl jumping in excitement with a shopping bag; \\n b.8K, Fashion portrait of two children dressed in sunflower yellow winter clothing, shivering from the cold as they stand next to their father, who is holding a snowboard, ready for a photo; \\n c.8K, Fashion portrait of an excited young woman standing next to her car; \\n d. 8K, Fashion portrait of a happy young Arab traditional family caresses the car, children jumping with joy; \\n e. 8K, Fashion portrait of a happy young man reclining on a car with one leg on the car;\\n f.8K, Fashion portrait of a joyful young man in a suit standing beside a woman in a golden dress. ##Prompt:```{prmpt}```\\n Write the final prompt in JSON format with the prompt key.\"\n",
    "\n",
    "    if rd == 'Generative Background Fill':\n",
    "        completion = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": gbf_ip_prmpt}\n",
    "        ]\n",
    "        )\n",
    "        input_text = completion.choices[0].message.content\n",
    "    else:\n",
    "        completion = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": ip_ip_prmpt}\n",
    "        ]\n",
    "        )\n",
    "        input_text = completion.choices[0].message.content\n",
    "\n",
    "    #print(input_text)\n",
    "    json_match = re.search(r'```json\\n({.*?})\\n```', input_text, re.DOTALL)\n",
    "    \n",
    "    if json_match:\n",
    "        json_str = json_match.group(1)\n",
    "        # print(\"----------\")\n",
    "        # print(type(json_str))\n",
    "        json_data = json.loads(json_str)\n",
    "        # print(\"----------\")\n",
    "        # print(type(json_data))\n",
    "        op_response = json_data[\"prompt\"]\n",
    "    else:\n",
    "       op_response =  input_text\n",
    "       \n",
    "    return op_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bckgrnd_gen(Im,bckgrnd_removal_prmpt,negative_prmpt,seed,output_format,ks): \n",
    "    image = cv2.imread(Im, cv2.IMREAD_UNCHANGED)\n",
    "    if image is not None:\n",
    "        print(\"Image loaded successfully!\")\n",
    "        print(\"Shape of the image:\", image.shape)\n",
    "        height, width, _ = image.shape\n",
    "        print(image.shape)\n",
    "\n",
    "        if image.shape[2] == 4:\n",
    "            alpha_channel = image[:, :, 3]\n",
    "            mask = alpha_channel == 0\n",
    "            mask = (mask * 255).astype(np.uint8)\n",
    "\n",
    "            kernel_size = int(ks)\n",
    "            kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "            dilated_mask = cv2.dilate(mask, kernel, iterations=7)\n",
    "            cv2.imwrite('data\\\\03_app_generated\\\\02_transparent_mask.png', dilated_mask)\n",
    "\n",
    "            white_background = np.ones((height, width, 3), dtype=np.uint8) * 255 \n",
    "            alpha_channel = image[:, :, 3] / 255.0\n",
    "            alpha_layer = np.stack([alpha_channel]*3, axis=-1)\n",
    "\n",
    "            foreground = (image[:, :, :3] * alpha_layer).astype(np.uint8)\n",
    "            background = (white_background * (1 - alpha_layer)).astype(np.uint8)\n",
    "            blended_image = cv2.add(foreground, background)\n",
    "            cv2.imwrite('data\\\\03_app_generated\\\\02_blended_image.png', blended_image)\n",
    "\n",
    "        else:\n",
    "            # mask = np.all(image == [0, 0, 0], axis=-1)\n",
    "            # white_mask = np.where(mask[..., None], [255, 255, 255], [0, 0, 0])\n",
    "            # gray_image = cv2.cvtColor(white_mask.astype(np.uint8), cv2.COLOR_BGR2GRAY)\n",
    "            # cv2.imwrite('transparent_mask.png', gray_image)\n",
    "\n",
    "            # blended_image = cv2.imread(Im, cv2.IMREAD_UNCHANGED)\n",
    "            # cv2.imwrite('blended_image.png', blended_image)\n",
    "            print(\"No Alpha Layer\")\n",
    "\n",
    "    image = Im\n",
    "    mask = \"data\\\\03_app_generated\\\\02_transparent_mask.png\"\n",
    "    prompt = bckgrnd_removal_prmpt\n",
    "    negative_prompt = negative_prmpt\n",
    "    seed = str(seed)\n",
    "    output_format = output_format\n",
    "\n",
    "    host = f\"https://api.stability.ai/v2beta/stable-image/edit/inpaint\"\n",
    "\n",
    "    params = {\n",
    "        \"image\" : image,\n",
    "        \"mask\" : mask,\n",
    "        \"negative_prompt\" : negative_prompt,\n",
    "        \"seed\" : seed,\n",
    "        \"mode\": \"mask\",\n",
    "        \"output_format\": output_format,\n",
    "        \"prompt\" : prompt\n",
    "    }\n",
    "\n",
    "    response = send_generation_request(\n",
    "        host,\n",
    "        params\n",
    "    )\n",
    "\n",
    "    # Decode response\n",
    "    output_image = response.content\n",
    "    finish_reason = response.headers.get(\"finish-reason\")\n",
    "    seed = response.headers.get(\"seed\")\n",
    "\n",
    "    # Check for NSFW classification\n",
    "    if finish_reason == 'CONTENT_FILTERED':\n",
    "        raise Warning(\"Generation failed NSFW classifier\")\n",
    "\n",
    "    # Save and display result\n",
    "    filename, _ = os.path.splitext(os.path.basename(image))\n",
    "    edited = f\"data\\\\03_app_generated\\\\BCG_{filename}_{seed}.{output_format}\"\n",
    "    with open(edited, \"wb\") as f:\n",
    "        f.write(output_image)\n",
    "\n",
    "    return edited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_inpainting(Im,prmpt,negative_prmpt,seed,output_format):\n",
    "    Im[\"composite\"].save('data\\\\03_app_generated\\\\composite_final.png')\n",
    "    Im[\"layers\"][0] = Im[\"layers\"][0].convert('L')\n",
    "    Im[\"layers\"][0].save('data\\\\03_app_generated\\\\mask_final.png')\n",
    "    Im[\"composite\"].save('data\\\\03_app_generated\\\\background_final.png')\n",
    "\n",
    "    mask_path = 'data\\\\03_app_generated\\\\mask_final.png'\n",
    "    with Image.open(mask_path) as mask:\n",
    "        gray_mask = mask.convert('L')  # Convert to grayscale\n",
    "        gray_mask.save('data\\\\03_app_generated\\\\IP_mask_white.png')\n",
    "\t\n",
    "    image = 'data\\\\03_app_generated\\\\background_final.png'\n",
    "    mask = 'data\\\\03_app_generated\\\\IP_mask_white.png'\n",
    "    \n",
    "    prompt = prmpt \n",
    "    negative_prompt = negative_prmpt\n",
    "    seed = int(seed) \n",
    "    output_format = output_format\n",
    "\n",
    "    host = f\"https://api.stability.ai/v2beta/stable-image/edit/inpaint\"\n",
    "\n",
    "    params = {\n",
    "        \"image\" : image,\n",
    "        \"mask\" : mask,\n",
    "        \"negative_prompt\" : negative_prompt,\n",
    "        \"seed\" : seed,\n",
    "        \"mode\": \"mask\",\n",
    "        \"output_format\": output_format,\n",
    "        \"prompt\" : prompt\n",
    "    }\n",
    "\n",
    "    response = send_generation_request(\n",
    "        host,\n",
    "        params\n",
    "    )\n",
    "\n",
    "    # Decode response\n",
    "    output_image = response.content\n",
    "    finish_reason = response.headers.get(\"finish-reason\")\n",
    "    seed = response.headers.get(\"seed\")\n",
    "\n",
    "    # Check for NSFW classification\n",
    "    if finish_reason == 'CONTENT_FILTERED':\n",
    "        raise Warning(\"Generation failed NSFW classifier\")\n",
    "\n",
    "    # Save and display result\n",
    "    filename, _ = os.path.splitext(os.path.basename(image))\n",
    "    edited = f\"edited_{filename}_{seed}.{output_format}\"\n",
    "\n",
    "    with open(edited, \"wb\") as f:\n",
    "        f.write(output_image)\n",
    "\n",
    "    return edited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data\\\\01_original\\\\gallery_images\\\\0.png', 'data\\\\01_original\\\\gallery_images\\\\00.png', 'data\\\\01_original\\\\gallery_images\\\\000.png', 'data\\\\01_original\\\\gallery_images\\\\000003.png', 'data\\\\01_original\\\\gallery_images\\\\001.png', 'data\\\\01_original\\\\gallery_images\\\\002.png', 'data\\\\01_original\\\\gallery_images\\\\006.png', 'data\\\\01_original\\\\gallery_images\\\\01.png', 'data\\\\01_original\\\\gallery_images\\\\03.png', 'data\\\\01_original\\\\gallery_images\\\\05.png', 'data\\\\01_original\\\\gallery_images\\\\06.png', 'data\\\\01_original\\\\gallery_images\\\\08.png', 'data\\\\01_original\\\\gallery_images\\\\1.png', 'data\\\\01_original\\\\gallery_images\\\\10.png', 'data\\\\01_original\\\\gallery_images\\\\11.png', 'data\\\\01_original\\\\gallery_images\\\\13.png', 'data\\\\01_original\\\\gallery_images\\\\14.png', 'data\\\\01_original\\\\gallery_images\\\\15.png', 'data\\\\01_original\\\\gallery_images\\\\16.png', 'data\\\\01_original\\\\gallery_images\\\\2.png', 'data\\\\01_original\\\\gallery_images\\\\20.png', 'data\\\\01_original\\\\gallery_images\\\\21.png', 'data\\\\01_original\\\\gallery_images\\\\22.png', 'data\\\\01_original\\\\gallery_images\\\\3.png', 'data\\\\01_original\\\\gallery_images\\\\4.png', 'data\\\\01_original\\\\gallery_images\\\\5.png', 'data\\\\01_original\\\\gallery_images\\\\50.png', 'data\\\\01_original\\\\gallery_images\\\\51.png', 'data\\\\01_original\\\\gallery_images\\\\52.png', 'data\\\\01_original\\\\gallery_images\\\\53.png', 'data\\\\01_original\\\\gallery_images\\\\55.png', 'data\\\\01_original\\\\gallery_images\\\\56.png', 'data\\\\01_original\\\\gallery_images\\\\57.png', 'data\\\\01_original\\\\gallery_images\\\\58.png', 'data\\\\01_original\\\\gallery_images\\\\59.png', 'data\\\\01_original\\\\gallery_images\\\\6.png', 'data\\\\01_original\\\\gallery_images\\\\60.png', 'data\\\\01_original\\\\gallery_images\\\\7.png', 'data\\\\01_original\\\\gallery_images\\\\8.png', 'data\\\\01_original\\\\gallery_images\\\\9.png']\n"
     ]
    }
   ],
   "source": [
    "def list_folder_contents(folder_path):\n",
    "    gallery_path_list = []\n",
    "    # Walk through all directories and files in the folder\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for name in files:\n",
    "            gallery_path_list.append(os.path.join(root, name))\n",
    "        for name in dirs:\n",
    "            gallery_path_list.append(os.path.join(root, name))\n",
    "    return gallery_path_list\n",
    "\n",
    "# Example usage\n",
    "folder_path = 'data\\\\01_original\\\\gallery_images\\\\'\n",
    "folder_contents = list_folder_contents(folder_path)\n",
    "print(folder_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"# blend.ai (Fractal Hackathon)\n",
    "        Enhance your marketing visuals effortlessly with Blend.ai, our state-of-the-art inpainting tool designed for seamless image edits. Transform your images into captivating masterpieces with precision and ease!\n",
    "        \"\"\")\n",
    "    with gr.Tab(\"Background Remover\"):\n",
    "        gr.Interface(fn=bckgrnd_removal,inputs=gr.Text(label=\"Image Path\"),outputs=gr.Image(format=\"png\", label=\"BG removed image\", show_download_button=True),allow_flagging=False,title=\"Background Remover\",description=\"Provide the path to a PNG image of your product. Our tool will automatically remove the background, making it perfect for professional presentations and marketing material.\")\n",
    "    with gr.Tab(\"Image Search\"):\n",
    "        gr.Interface(fn=search_image,inputs=gr.Text(label=\"Prompt\"),outputs=gr.Gallery(label=\"Similar image\"),allow_flagging=False,title=\"Image Search\",description=\"Search and retrieve images based on your text prompts. Ideal for finding specific product shots or design inspirations. Example prompts are included for quick testing.\",examples=['toyota corolla blue cross 30 degree closeup shot', 'Toyota 2024 Land Cruiser 270 black degree normal shot', 'nissan two tone monarch orange left normal shot'])\n",
    "    with gr.Tab(\"Generative Background Fill\"):\n",
    "        gr.Interface(fn=bckgrnd_gen,inputs=[gr.Text(label=\"Image Path\"),gr.TextArea(label=\"Prompt\"),gr.Text(label=\"Negative Prompt\",value=\"noisy, blurry, unattractive, sloppy, unprofessional, low quality\"),gr.Text(label=\"Seed\",value=\"0\"),gr.Text(label=\"Output Format\",value='png'),gr.Slider(minimum=0,maximum=10,value=2,step=1,label=\"Kernal Size\",show_label=True,info=\"Adjust Kernel size\")],outputs=[gr.Image(format=\"png\",show_download_button=True)],allow_flagging='never',title=\"Generative Background Fill\",description=\"Upload an RGBA PNG image to add a custom background. Provide a positive prompt for desired elements, a negative prompt to exclude elements, and customize the output with our sliders.\")\n",
    "    with gr.Tab(\"Inpaint Characters\"):\n",
    "        gr.Interface(fn=character_inpainting,inputs=[gr.ImageMask(type='pil', brush=gr.Brush(colors=[\"#ffffff\"], color_mode=\"fixed\"),sources = 'upload'),gr.TextArea(label=\"Prompt\"),gr.Text(label=\"Negative Prompt\",value=\"noisy, blurry, unattractive, sloppy, unprofessional, low quality\"),gr.Text(label=\"Seed\",value=\"0\"),gr.Text(label=\"Output Format\",value='png')],outputs=\"image\",title=\"Inpaint Characters\",description=\"Start by uploading an image you've enhanced in the Generative Background Fill section. Use the masking tool to designate the specific area where you wish to add new characters or elements. Then, provide a detailed prompt for the inpainting process.\",allow_flagging='never')\n",
    "    with gr.Tab(\"Gallery\"):\n",
    "        gr.Gallery(value=folder_contents, columns=[4], rows=[10], object_fit=\"contain\", height=\"auto\")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Tab(\"Prompt Enhancer\"):\n",
    "        gr.Interface(fn=prmpt_enhancer,inputs=[gr.Radio([\"Generative Background Fill\", \"Inpaint Characters\"], label=\"Section\", info=\"Select the section for which you need to enhance prompt\"), gr.Text(label=\"Prompt\")],outputs=[gr.Text(label=\"Enhanced Prompt\")],allow_flagging='never',title=\"Prompt Enhancer\",description=\"Enhance your prompts to improve clarity and specificity. Select the type of enhancement and enter your initial prompt.\")\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
